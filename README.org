:PROPERTIES:
:header-args: :results verbatim :exports both
:END:
#+title: its-jointprobability
#+EXPORT_EXCLUDE_TAGS: noexport

A Bayesian approach to generating metadata for educational materials.

This project is primarily intended to be used as a microservice through the ~nix~ package. Additionally, it includes some CLI utilities in order to (re-) train the model for some data (data not included).

* Utils :noexport:
#+name: format-json
#+begin_src shell sh :var result="" :results verbatim
echo $result | json
#+end_src

#+name: format-prediction
#+begin_src python :var result="" :results output :session python-jointprobability-demo
import json
import pandas as pd
# always use the same formatting for numbers 
pd.set_option('display.float_format', lambda x: '%.3f' % x)

result_dict = json.loads(result)["predictions"]
for key, value in sorted(list(result_dict.items())):
    print(key)
    print("--------------------------------------------------------------------")
    df = pd.DataFrame.from_dict(value).set_index("name")
    df = df.drop("id", axis=1)
    df["prob_interval"] = df.apply(lambda x: [f"{y:g}" for y in x["prob_interval"]], axis=1)
    print(df.to_string())
    print()
#+end_src

* Usage

** Service

With ~Nix~, no further installation is required to run the microservice. Simply run the following command:
#+begin_src shell
nix run github:openeduhub/its-jointprobability
#+end_src
or optionally, with CUDA support:
#+begin_src shell
nix run "github:openeduhub/its-jointprobability#with-cuda"
#+end_src

If the package has been installed locally, the service is also available as ~its-jointprobability~ from the command line.

For more information on configuration options, see
#+begin_src shell
nix run github:openeduhub/its-jointprobability -- --help
#+end_src

Once started, see the ~Swagger~ UI for documentation on the service.
It is located on =http://localhost:8080/docs= by default.

** Model Training

To retrain the model under some data, use the included ~retrain-model~ CLI tool, e.g. through
#+begin_src shell
nix run "github:openeduhub/its-jointprobability#retrain-model" -- <path/to/data-dir>
#+end_src
or, *highly recommended*, with CUDA:
#+begin_src shell
nix run "github:openeduhub/its-jointprobability#retrain-model-with-cuda" -- <path/to/data-dir>
#+end_src

The utility will look for =train_data= and =train_labels=, which are assumed to files that can be loaded through [[https://pytorch.org/docs/stable/generated/torch.load.html][torch.load]]. These should be (=float=-type) [[https://pytorch.org/docs/stable/tensors.html#torch.Tensor][torch.Tensor]] objects with the following content:
- ~train_data_labeled~ :: a two-dimensional =Tensor= where the first dimension corresponds to the individual documents to use for training and the second dimensions contains each document's content, encoded through their Bag-of-words representation.
- ~train_targets~ :: a two-dimensional =Tensor= where the first dimension corresponds to the individual documents to use for training and the second dimension encodes whether each document belongs to each discipline (=1.0= if it does, =0.0= otherwise).

Once the data has been loaded, the topic model will be trained (this will take a long time) and saved within the set directory under =prodslda=. If this file already exists, this step is skipped.

Finally, the Bayesian classification model is trained and saved under =classification=. At this point, some quality metrics will be computed for the model on the training data. If ~test_data_labeled~ and ~test_targets~ are present in the given directory (analogous to the training data), these quality metrics will also be computed for this testing data.

** As a Python Library
:PROPERTIES:
:header-args: :session *python:its-jointprobability-demo* :results output :exports both :async yes
:END:

When doing larger scale analysis, using the model through a REST API may not be very convenient, especially because of the lack of proper parallelization of batches and thus much higher hardware utilization than would be possible.

For such use-cases, using the Python library directly is recommended. See [[Python Library]] for details on how to install the library through the provided ~nixpkgs~ overlay. Alternatively, using ~pip~ may also work.

*** For Inference

To load a pre-trained model, e.g. from https://gitlab.gwdg.de/jopitz/its-jointprobability-model, load the corresponding =ProdSLDA_{kwargs|pyro|state}.pt= files using ~its_jointprobability.data.load_model~:

#+begin_src python
from pathlib import Path
import torch
from its_jointprobability.models.prodslda import ProdSLDA
from its_jointprobability.data import load_model

model_path = Path("../its-jointprobability-model")
# use CUDA if it is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = load_model(ProdSLDA, model_path, device=device)

print(model)
#+end_src

#+RESULTS:
#+begin_example
ProdSLDA(
  (decoder): Sequential(
    (0): Linear(in_features=500, out_features=1000, bias=True)
    (1): Tanh()
    (2): Dropout(p=0.6, inplace=False)
    (3): Linear(in_features=1000, out_features=20918, bias=True)
    (4): BatchNorm1d(20918, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (5): Softmax(dim=-1)
  )
  (encoder): Sequential(
    (0): Linear(in_features=20918, out_features=1000, bias=True)
    (1): Tanh()
    (2): Dropout(p=0.6, inplace=False)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
)
#+end_example

Now, we can run inference on arbitrary texts by simply using the ~predict_from_texts~ method of the model:
#+begin_src python :exports both
texts = [
    "Der Satz des Pythagoras lautet: a^2 + b^2 = c^2",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.",
]

predictions = list(
    model.predict_from_texts(*texts, tokens=model.vocab, num_samples=1000)
)
#+end_src

#+RESULTS:
: posterior sample: 100% 4/4 [00:03<00:00,  1.14it/s]
: posterior sample: 100% 19/19 [00:17<00:00,  1.07it/s]

#+begin_src python :exports both
from pprint import pprint

# print the most relevant predictions for the school discipline
print("Most relevant")
print("-------------")
for text, prediction in zip(texts, predictions):
    print(text)
    pprint(
        sorted(
            prediction["properties.ccm:taxonid"],
            key=lambda x: x.baseline_diff,
            reverse=True,
        )[:5]
    )
    print()
    
# print the least relevant predictions for the school discipline
print("Least relevant")
print("--------------")
for text, prediction in zip(texts, predictions):
    print(text)
    pprint(
        sorted(
            prediction["properties.ccm:taxonid"],
            key=lambda x: x.baseline_diff,
            reverse=False,
        )[:5]
    )
    print()
#+end_src

#+RESULTS:
#+begin_example
Most relevant
-------------
Der Satz des Pythagoras lautet: a^2 + b^2 = c^2
[Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/340', name='Interkulturelle Bildung', mean_prob=0.004334829282015562, median_prob=9.120339382207021e-05, baseline_diff=0.0030616573058068752, prob_interval=[4.6206855586206075e-07, 0.0018172900890931487]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/64018', name='Nachhaltigkeit', mean_prob=0.023164156824350357, median_prob=0.001953881699591875, baseline_diff=0.003055572509765625, prob_interval=[2.6131787308258936e-05, 0.019906286150217056]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/44007', name='Sozialpädagogik', mean_prob=0.0015436196699738503, median_prob=2.4345483780052746e-06, baseline_diff=1.8388847820460796e-05, prob_interval=[1.6854352580253362e-08, 2.5675706638139673e-05]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/04011', name='Metalltechnik', mean_prob=1.6211757447820527e-15, median_prob=4.5803614962629504e-23, baseline_diff=-1.5082068927085857e-10, prob_interval=[0.0, 4.153199538620593e-20]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/680', name='Weiterbildung', mean_prob=1.5082253668197154e-08, median_prob=3.1716205942521882e-24, baseline_diff=-8.739033319216105e-07, prob_interval=[0.0, 1.4223026512789792e-20])]

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
[Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/64018', name='Nachhaltigkeit', mean_prob=0.07391101121902466, median_prob=0.007469822186976671, baseline_diff=0.053802426904439926, prob_interval=[9.094269626075402e-05, 0.09301026910543442]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/320', name='Informatik', mean_prob=0.0835675522685051, median_prob=0.0531136579811573, baseline_diff=0.022378355264663696, prob_interval=[0.006001325789839029, 0.1226702407002449]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/420', name='Musik', mean_prob=0.05973250791430473, median_prob=0.013322144746780396, baseline_diff=0.02026599645614624, prob_interval=[0.00011374019231880084, 0.05160485580563545]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/340', name='Interkulturelle Bildung', mean_prob=0.01318682823330164, median_prob=0.00016035181761253625, baseline_diff=0.011913656257092953, prob_interval=[5.694200311268105e-08, 0.005958986468613148]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/380', name='Mathematik', mean_prob=0.05462333932518959, median_prob=0.03491808474063873, baseline_diff=0.00886915996670723, prob_interval=[0.0019203750416636467, 0.08943411707878113])]

Least relevant
--------------
Der Satz des Pythagoras lautet: a^2 + b^2 = c^2
[Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/240', name='Geschichte', mean_prob=0.10317816585302353, median_prob=0.056241724640131, baseline_diff=-0.1918398141860962, prob_interval=[0.0043996660970151424, 0.17424429953098297]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/720', name='Allgemein', mean_prob=0.24014437198638916, median_prob=0.17383265495300293, baseline_diff=-0.17389711737632751, prob_interval=[0.017807582393288612, 0.40856990218162537]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/060', name='Kunst', mean_prob=0.01866566203534603, median_prob=0.0070883892476558685, baseline_diff=-0.09509199857711792, prob_interval=[0.0005538795958273113, 0.017943987622857094]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/900', name='Medienbildung', mean_prob=0.011733775027096272, median_prob=0.0030990708619356155, baseline_diff=-0.068480484187603, prob_interval=[0.00033362465910613537, 0.008431673981249332]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/080', name='Biologie', mean_prob=0.0064823017455637455, median_prob=0.0015182377537712455, baseline_diff=-0.04947914555668831, prob_interval=[0.000152547363541089, 0.003562761005014181])]

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
[Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/240', name='Geschichte', mean_prob=0.17352108657360077, median_prob=0.10049775242805481, baseline_diff=-0.12149690091609955, prob_interval=[0.01182160060852766, 0.31308022141456604]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/720', name='Allgemein', mean_prob=0.34916651248931885, median_prob=0.2885059416294098, baseline_diff=-0.06487497687339783, prob_interval=[0.04611716791987419, 0.6247345209121704]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/080', name='Biologie', mean_prob=0.011639222502708435, median_prob=0.004672432783991098, baseline_diff=-0.04432222619652748, prob_interval=[0.0004902555956505239, 0.010195090435445309]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/900', name='Medienbildung', mean_prob=0.04231301695108414, median_prob=0.019437743350863457, baseline_diff=-0.037901245057582855, prob_interval=[0.0017333182040601969, 0.051200296729803085]),
 Prediction_Score(id='http://w3id.org/openeduhub/vocabs/discipline/120', name='Deutsch', mean_prob=0.017739182338118553, median_prob=0.012929452583193779, baseline_diff=-0.03140529990196228, prob_interval=[0.0008402393432334065, 0.024917293339967728])]
#+end_example

* REST API
:PROPERTIES:
:header-args: :results verbatim :exports both :post format-json(result=*this*) :wrap src
:END:

** Ping

Once the service has started, we can ping it to check that it is responding to requests:
#+begin_src shell :post :exports both
curl -i -X GET http://localhost:8080/_ping
#+end_src

#+RESULTS:
#+begin_src
HTTP/1.1 200 OK
date: Mon, 15 Jan 2024 15:34:05 GMT
server: uvicorn
content-length: 4
content-type: application/json

null
#+end_src

** Predictions
:PROPERTIES:
:header-args: :results verbatim :exports both :post format-prediction(result=*this*)
:END:

With the =/predict= endpoint, we can send a text to the model. For readability, we only ask for the seven most relevant categories for each metadata field.

In addition to the identifiers of the predicted metadata, we also get some diagnostics that help us understand whether this is a relevant match (in principle, all categories are always returned). Specifically, we gain two point-estimates (mean and median) for the probability of the category belonging to the given text, according to the model. We also get the difference to the "baseline" (i.e. an empty text) and a credibility interval (by default 80%) on said probability.

In the example below, we get only one relevant school discipline, which is also the one we would be expecting for the text (Mathematics). Because the text is relatively short, the probability of this fit is still relatively low. We also get a strong match *against* primary school (indicated by the large negative difference to the baseline probability), which is also what we would expect, given that Pythagoras' Theorem is usually covered in middle school and above.
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "Der Satz des Pythagoras lautet: a^2 + b^2 = c^2. Er wird benutzt, um die Hypotenuse eines rechtwinkligen Dreiecks zu berechnen.",
  "num_predictions": "7"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                                mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                             
Mathematik                          0.021        0.004          0.013    [1.57953e-05, 0.0164169]
Feste, Bräuche und Traditionen      0.002        0.000         -0.001  [4.10109e-10, 1.98745e-06]
Biologie                            0.001        0.001         -0.087   [5.07025e-05, 0.00171817]
Qualitative Nachweisverfahren       0.001        0.000          0.001  [4.49282e-12, 2.92348e-07]
Länder, Regionen und Städte         0.001        0.000         -0.004  [7.34517e-13, 2.26798e-08]
Der Mensch                          0.001        0.000         -0.016  [5.73006e-07, 0.000592266]
Mathematik                          0.001        0.000         -0.010   [7.3422e-09, 0.000170847]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                 
Sekundarstufe I         0.745        0.756         -0.029        [0.633408, 0.890434]
Sekundarstufe II        0.566        0.569         -0.079         [0.41589, 0.713344]
Primarstufe             0.052        0.046         -0.804      [0.0207947, 0.0725422]
Berufliche Bildung      0.022        0.019         -0.047     [0.00718854, 0.0306739]
Erwachsenenbildung      0.010        0.007         -0.032     [0.00194674, 0.0122298]
Hochschule              0.008        0.006         -0.025     [0.00117875, 0.0109949]
Elementarbereich        0.000        0.000         -0.092  [3.30024e-05, 0.000420535]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lerner/in       0.988        0.989          0.053         [0.982577, 0.99521]
Lehrer/in       0.827        0.854          0.499        [0.751678, 0.960841]
Eltern          0.079        0.064         -0.404        [0.0217913, 0.11293]
Berater/in      0.000        0.000         -0.041  [4.90002e-06, 0.000374989]
andere          0.000        0.000         -0.002  [1.78784e-12, 1.06778e-09]
Autor/in        0.000        0.000         -0.001  [9.59522e-14, 4.59313e-10]
Verwaltung      0.000        0.000         -0.002   [3.3975e-12, 8.27768e-10]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff             prob_interval
name                                                                                                 
Erklärvideo und gefilmtes Experiment      0.502        0.494          0.301     [0.0773246, 0.751183]
Arbeitsblatt                              0.375        0.354          0.256      [0.102882, 0.570369]
Unterrichtsbaustein                       0.365        0.359          0.143      [0.155787, 0.527744]
Tool                                      0.142        0.099         -0.008     [0.0110758, 0.211934]
Material                                  0.083        0.064         -0.361    [0.00947135, 0.114135]
Kurs                                      0.048        0.018          0.004  [0.000430892, 0.0595212]
Webseite                                  0.040        0.028         -0.074   [0.00583286, 0.0531787]

properties.ccm:taxonid
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff            prob_interval
name                                                                      
Mathematik      0.950        0.968          0.909     [0.925755, 0.996444]
Chemie          0.079        0.063          0.069    [0.0156914, 0.115803]
Informatik      0.036        0.027         -0.018  [0.00725047, 0.0432274]
Physik          0.028        0.020          0.012  [0.00393672, 0.0412468]
Allgemein       0.016        0.014         -0.290   [0.00443254, 0.022432]
Politik         0.010        0.008         -0.112  [0.00289255, 0.0133154]
Deutsch         0.008        0.007         -0.046  [0.00224648, 0.0110554]
#+end_example

Note that these predictions are stochastic, so another run on the same text may yield slightly different predictions:
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "Der Satz des Pythagoras lautet: a^2 + b^2 = c^2. Er wird benutzt, um die Hypotenuse eines rechtwinkligen Dreiecks zu berechnen.",
  "num_predictions": "7"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                                              mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                                           
Kernspaltung                                      0.004        0.000          0.002  [3.88072e-11, 5.38947e-07]
Bernoulli-Experimente und Binomialverteilung      0.004        0.000          0.004  [9.59279e-17, 1.17127e-10]
Russland                                          0.004        0.000          0.001  [3.06271e-12, 2.92418e-06]
Biodiversität und Artenschutz                     0.003        0.000          0.002   [4.15973e-10, 6.6697e-07]
Peripherie                                        0.002        0.000         -0.005  [8.13734e-14, 1.92165e-09]
Big Data                                          0.002        0.000         -0.002  [1.58056e-17, 1.87404e-11]
Kunst                                             0.002        0.000         -0.012  [2.04735e-10, 1.08753e-05]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                 
Sekundarstufe I         0.658        0.671         -0.117        [0.537717, 0.804029]
Sekundarstufe II        0.540        0.543         -0.105        [0.402108, 0.670748]
Primarstufe             0.093        0.080         -0.763        [0.0328194, 0.12767]
Berufliche Bildung      0.016        0.014         -0.053     [0.00674256, 0.0224897]
Hochschule              0.010        0.008         -0.023     [0.00177927, 0.0143344]
Erwachsenenbildung      0.004        0.003         -0.038   [0.000978975, 0.00558737]
Elementarbereich        0.001        0.000         -0.092  [0.000101135, 0.000913618]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lerner/in       0.986        0.989          0.051        [0.981248, 0.996024]
Lehrer/in       0.844        0.865          0.516        [0.781273, 0.962713]
Eltern          0.019        0.016         -0.464     [0.00635502, 0.0254503]
Berater/in      0.000        0.000         -0.041  [9.01278e-06, 0.000419059]
Verwaltung      0.000        0.000         -0.002  [1.45516e-09, 3.21964e-07]
andere          0.000        0.000         -0.002  [6.70685e-13, 1.08625e-08]
Autor/in        0.000        0.000         -0.001  [1.75059e-13, 3.69563e-11]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff            prob_interval
name                                                                                                
Erklärvideo und gefilmtes Experiment      0.520        0.506          0.319     [0.207993, 0.848928]
Material                                  0.187        0.163         -0.256     [0.045449, 0.281651]
Arbeitsblatt                              0.156        0.120          0.037      [0.023703, 0.24397]
Unterrichtsbaustein                       0.116        0.098         -0.106    [0.0288655, 0.172656]
Wiki (dynamisch)                          0.059        0.042          0.024  [0.00737023, 0.0805252]
Dokumente und textbasierte Inhalte        0.040        0.030         -0.042  [0.00523113, 0.0521117]
Bild (Material)                           0.032        0.017         -0.250  [0.00170562, 0.0422827]

properties.ccm:taxonid
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff             prob_interval
name                                                                       
Mathematik      0.947        0.966          0.906      [0.927992, 0.997892]
Physik          0.069        0.051          0.053    [0.0124708, 0.0988244]
Chemie          0.041        0.027          0.031   [0.00308316, 0.0581905]
Geschichte      0.032        0.026         -0.244    [0.0080951, 0.0459374]
Informatik      0.019        0.016         -0.034   [0.00507606, 0.0280774]
Politik         0.017        0.012         -0.105   [0.00438061, 0.0223068]
Allgemein       0.006        0.006         -0.300  [0.00253889, 0.00889731]
#+end_example

To reduce this variance, we can increase the number of samples being drawn for the prediction. Note that the computation time is roughly proportional to the number of such samples. By default, 500 samples are drawn.
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "Der Satz des Pythagoras lautet: a^2 + b^2 = c^2. Er wird benutzt, um die Hypotenuse eines rechtwinkligen Dreiecks zu berechnen.",
  "num_predictions": "7",
  "num_samples": "10000"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                               mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                            
Permanentmagnetismus               0.006        0.000          0.004  [1.04805e-25, 4.20079e-09]
Flächen berechnen                  0.003        0.000         -0.000  [2.95401e-31, 3.58257e-10]
Mathematik                         0.002        0.000         -0.009  [4.77203e-19, 3.10909e-05]
Biologie                           0.002        0.000         -0.086  [3.09773e-08, 0.000823177]
Museen                             0.001        0.000         -0.000  [1.19061e-22, 4.61681e-08]
Dreißigjähriger Krieg              0.001        0.000         -0.001  [7.93544e-31, 1.15993e-11]
Strategien im Kunstunterricht      0.001        0.000         -0.036  [1.69029e-19, 1.58991e-06]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                 
Sekundarstufe I         0.700        0.731         -0.075        [0.546017, 0.910156]
Sekundarstufe II        0.618        0.623         -0.027        [0.435185, 0.816913]
Primarstufe             0.103        0.083         -0.753       [0.0172355, 0.153677]
Hochschule              0.021        0.012         -0.013    [0.000441675, 0.0278903]
Erwachsenenbildung      0.020        0.012         -0.022     [0.00113011, 0.0264025]
Berufliche Bildung      0.020        0.014         -0.049     [0.00206414, 0.0305485]
Förderschule            0.001        0.000         -0.023  [1.11897e-08, 0.000181539]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lerner/in       0.991        0.993          0.055        [0.986292, 0.998885]
Lehrer/in       0.682        0.735          0.354         [0.476891, 0.95681]
Eltern          0.025        0.017         -0.458     [0.00199726, 0.0356875]
Berater/in      0.000        0.000         -0.041  [1.59186e-09, 0.000310855]
Autor/in        0.000        0.000         -0.001  [4.54655e-16, 7.02791e-09]
Verwaltung      0.000        0.000         -0.002  [5.77959e-15, 1.55868e-08]
andere          0.000        0.000         -0.002  [5.45679e-17, 2.62077e-08]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff             prob_interval
name                                                                                                 
Erklärvideo und gefilmtes Experiment      0.536        0.534          0.334      [0.208624, 0.901041]
Arbeitsblatt                              0.348        0.311          0.229      [0.035206, 0.562197]
Unterrichtsbaustein                       0.144        0.106         -0.078    [0.00983227, 0.220326]
Material                                  0.130        0.100         -0.314    [0.00784556, 0.202715]
Tool                                      0.059        0.026         -0.091  [0.000211047, 0.0863653]
Übungsmaterial                            0.037        0.028         -0.028   [0.00454333, 0.0537201]
Bild (Material)                           0.036        0.014         -0.246  [0.000189202, 0.0477068]

properties.ccm:taxonid
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff             prob_interval
name                                                                       
Mathematik      0.876        0.931          0.835      [0.795973, 0.999438]
Physik          0.041        0.023          0.025  [0.000610045, 0.0581255]
Chemie          0.019        0.010          0.009  [0.000168051, 0.0253653]
Allgemein       0.015        0.011         -0.292  [0.000637099, 0.0201304]
Geschichte      0.013        0.010         -0.263    [0.0021849, 0.0183837]
Informatik      0.011        0.006         -0.042   [0.00048636, 0.0156733]
Deutsch         0.009        0.005         -0.045  [0.000512807, 0.0113118]
#+end_example

Second run, for comparison
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "Der Satz des Pythagoras lautet: a^2 + b^2 = c^2. Er wird benutzt, um die Hypotenuse eines rechtwinkligen Dreiecks zu berechnen.",
  "num_predictions": "7",
  "num_samples": "10000"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                           mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                        
Mathematik                     0.007        0.000         -0.002  [6.97069e-18, 0.000686642]
Mathematik                     0.006        0.000         -0.005   [3.76969e-15, 0.00024075]
Interferenz                    0.004        0.000          0.003   [2.5436e-20, 2.46894e-08]
Folgen und Reihen              0.003        0.000          0.003  [5.95289e-33, 3.10162e-08]
Kreise                         0.003        0.000          0.001  [7.04356e-31, 1.25325e-11]
Beschleunigte Bewegungen       0.003        0.000         -0.003  [1.41952e-14, 2.06545e-06]
Entwicklung der Lebewesen      0.002        0.000         -0.006  [6.84777e-24, 3.14856e-10]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff              prob_interval
name                                                                                
Sekundarstufe I         0.714        0.728         -0.061       [0.578658, 0.901993]
Sekundarstufe II        0.598        0.612         -0.047       [0.407055, 0.813878]
Primarstufe             0.110        0.087         -0.746      [0.0174815, 0.168441]
Erwachsenenbildung      0.019        0.012         -0.023      [0.001115, 0.0275326]
Berufliche Bildung      0.019        0.013         -0.050    [0.00119974, 0.0269246]
Hochschule              0.013        0.008         -0.020   [0.000793146, 0.0182822]
Elementarbereich        0.001        0.000         -0.091  [2.45717e-07, 0.00119983]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lerner/in       0.993        0.995          0.057        [0.988731, 0.999468]
Lehrer/in       0.751        0.787          0.423        [0.613323, 0.959369]
Eltern          0.023        0.015         -0.460     [0.00139893, 0.0311014]
Berater/in      0.000        0.000         -0.041   [3.63725e-08, 0.00020787]
Verwaltung      0.000        0.000         -0.002  [8.04056e-13, 6.47553e-08]
Autor/in        0.000        0.000         -0.001  [1.94279e-16, 1.25903e-08]
andere          0.000        0.000         -0.002  [1.94291e-16, 1.28042e-08]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff             prob_interval
name                                                                                                 
Erklärvideo und gefilmtes Experiment      0.554        0.555          0.353      [0.225363, 0.906397]
Arbeitsblatt                              0.321        0.285          0.202      [0.038005, 0.513525]
Unterrichtsbaustein                       0.141        0.106         -0.081     [0.0119416, 0.218449]
Material                                  0.116        0.081         -0.328    [0.00607636, 0.178373]
Tool                                      0.057        0.027         -0.093  [0.000270257, 0.0812645]
Kurs                                      0.050        0.014          0.005  [5.22128e-05, 0.0539818]
Dokumente und textbasierte Inhalte        0.034        0.020         -0.048   [0.00114516, 0.0480636]

properties.ccm:taxonid
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff             prob_interval
name                                                                       
Mathematik      0.902        0.939          0.861        [0.8505, 0.998314]
Physik          0.036        0.020          0.020  [0.000903905, 0.0480465]
Chemie          0.022        0.013          0.012   [0.00111113, 0.0302186]
Allgemein       0.018        0.011         -0.289   [0.00171748, 0.0260492]
Geschichte      0.014        0.010         -0.262   [0.00178067, 0.0214405]
Informatik      0.011        0.006         -0.042  [0.000402587, 0.0150789]
Deutsch         0.007        0.003         -0.047  [0.000289367, 0.0092897]
#+end_example

You may notice that the probabilities for some other, less fitting, categories, are still relatively high. This is because the text is relatively short, so the model cannot conclude that e.g. a particular resource type does not fit. This behavior becomes more extreme the shorter the given text is. Essentially, the model has been given too little data to decide for or against any one category. This can also be seen in low differences to the baseline probabilities and large credibility interval.

For an even more extreme example, see the following, empty text, which corresponds to the baseline, when no information is given.
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "",
  "num_predictions": "10",
  "num_samples": "10000"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                                       mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                                    
Biologie                                   0.073        0.003         -0.015    [8.12617e-10, 0.0472828]
Entwicklung der Lebewesen                  0.060        0.000          0.051  [4.21656e-35, 9.01376e-07]
Strategien im Kunstunterricht              0.059        0.001          0.021    [1.34519e-10, 0.0243552]
Ökosysteme und Umweltschutz                0.055        0.000          0.052            [0, 4.06556e-10]
Batterien                                  0.054        0.000          0.046            [0, 1.24668e-08]
Sprachmittlung                             0.044        0.000          0.042  [6.79272e-29, 1.86358e-06]
Fahren, Rollen, Gleiten                    0.034        0.000          0.031             [0, 7.2549e-10]
Mathematik                                 0.032        0.000          0.021  [3.47168e-35, 1.90858e-05]
Theatertheorie                             0.032        0.000          0.029  [6.70069e-21, 0.000290813]
Musik (selbst) gestalten: Musikpraxis      0.027        0.000          0.024   [2.6483e-36, 1.47582e-06]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                 
Primarstufe             0.825        0.873         -0.031        [0.702206, 0.999168]
Sekundarstufe I         0.733        0.756         -0.042         [0.58574, 0.955443]
Sekundarstufe II        0.692        0.715          0.047        [0.527351, 0.925802]
Elementarbereich        0.179        0.104          0.087     [0.000890582, 0.308116]
Berufliche Bildung      0.088        0.074          0.019        [0.010181, 0.128394]
Erwachsenenbildung      0.045        0.026          0.004     [0.00219355, 0.0596329]
Hochschule              0.028        0.015         -0.005    [0.000190369, 0.0426328]
Förderschule            0.021        0.003         -0.003    [3.03745e-06, 0.0152756]
Fortbildung             0.003        0.001         -0.002   [3.93962e-07, 0.00241431]
Fernunterricht          0.002        0.000          0.000  [9.36978e-26, 7.78213e-11]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lerner/in       0.947        0.959          0.012        [0.925921, 0.996854]
Eltern          0.423        0.389         -0.060        [0.139725, 0.660639]
Lehrer/in       0.339        0.315          0.011       [0.0467053, 0.551711]
Berater/in      0.013        0.002         -0.029    [1.24258e-06, 0.0100754]
andere          0.007        0.000          0.005  [4.55889e-10, 0.000272175]
Verwaltung      0.003        0.000          0.000  [5.99627e-08, 0.000410005]
Autor/in        0.002        0.000          0.001  [4.01697e-12, 0.000175867]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff            prob_interval
name                                                                                                
Audio                                     0.557        0.585          0.038      [0.26518, 0.891834]
Material                                  0.533        0.545          0.089     [0.292179, 0.792951]
Unterrichtsbaustein                       0.226        0.143          0.004    [0.0139591, 0.369045]
Bild (Material)                           0.208        0.138         -0.074    [0.0108211, 0.325288]
Tool                                      0.184        0.096          0.034   [0.00213102, 0.296752]
Radio, Podcastfolge und Interview         0.182        0.111         -0.012  [0.000379695, 0.304063]
Arbeitsblatt                              0.170        0.123          0.051    [0.0183629, 0.264327]
Erklärvideo und gefilmtes Experiment      0.158        0.103         -0.044    [0.0169539, 0.213265]
Unterrichtsidee                           0.111        0.065          0.013   [0.00254748, 0.157927]
Lern-App                                  0.110        0.014          0.037  [8.67775e-13, 0.141215]

properties.ccm:taxonid
--------------------------------------------------------------------
               mean_prob  median_prob  baseline_diff             prob_interval
name                                                                          
Allgemein          0.360        0.333          0.053     [0.0820824, 0.556562]
Geschichte         0.270        0.236         -0.006     [0.0391924, 0.425642]
Politik            0.129        0.086          0.007     [0.0104066, 0.186623]
Kunst              0.109        0.052         -0.024    [0.00140644, 0.157905]
Medienbildung      0.086        0.023          0.006    [0.00020318, 0.114585]
Informatik         0.062        0.039          0.009    [0.00258989, 0.092882]
Musik              0.060        0.017          0.019  [3.04969e-05, 0.0732618]
Biologie           0.058        0.018         -0.007  [0.000912118, 0.0566149]
Deutsch            0.055        0.030          0.001   [0.00291097, 0.0760775]
Ethik              0.054        0.024          0.001  [0.000426072, 0.0756461]
#+end_example

The individual probabilities of the categories do not add up to 1. This is intended, as assigning a text multiple (or no) relevant categories is often desired. As an example, take the following paragraph taken from [[https://de.wikipedia.org/wiki/Deutschland][the German Wikipedia page on Germany]]. This is mostly about the history of Germany, but because it also covers relatively recent developments, it may also be relevant to politics.
#+begin_src shell :exports both
curl -X 'POST' \
  'http://localhost:8080/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "Die rasche Entwicklung vom Agrar- zum Industriestaat vollzog sich während der Gründerzeit in der zweiten Hälfte des 19. Jahrhunderts. Nach dem Ersten Weltkrieg wurde 1918 die Monarchie abgeschafft und die demokratische Weimarer Republik konstituiert. Ab 1933 führte die nationalsozialistische Diktatur zu politischer und rassistischer Verfolgung und gipfelte in der Ermordung von sechs Millionen Juden und Angehörigen anderer Minderheiten wie Sinti und Roma. Der vom NS-Staat 1939 begonnene Zweite Weltkrieg endete 1945 mit der Niederlage der Achsenmächte. Das von den Siegermächten besetzte Land wurde 1949 geteilt, nachdem bereits 1945 seine Ostgebiete teils unter polnische, teils sowjetische Verwaltungshoheit gestellt worden waren. Der Gründung der Bundesrepublik als demokratischer westdeutscher Teilstaat mit Westbindung am 23. Mai 1949 folgte die Gründung der sozialistischen DDR am 7. Oktober 1949 als ostdeutscher Teilstaat unter sowjetischer Hegemonie. Die innerdeutsche Grenze war nach dem Berliner Mauerbau (ab 13. August 1961) abgeriegelt. Nach der friedlichen Revolution in der DDR 1989 erfolgte die Lösung der deutschen Frage durch die Wiedervereinigung beider Landesteile am 3. Oktober 1990, womit auch die Außengrenzen Deutschlands als endgültig anerkannt wurden. Durch den Beitritt der fünf ostdeutschen Länder sowie die Wiedervereinigung von Ost- und West-Berlin zur heutigen Bundeshauptstadt zählt die Bundesrepublik Deutschland seit 1990 sechzehn Bundesländer.",
  "num_predictions": "7",
  "num_samples": "10000"
}'
#+end_src

#+RESULTS:
#+begin_example
properties.ccm:curriculum
--------------------------------------------------------------------
                                mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                             
Deutschland 1949 - 1990             0.127        0.000          0.127    [4.00072e-15, 0.0626132]
Mathematik                          0.048        0.000          0.039  [3.27168e-22, 1.26837e-05]
Stadtgeschichte                     0.046        0.000          0.045   [1.95837e-14, 0.00149554]
Russland                            0.034        0.000          0.032  [1.33971e-21, 3.15394e-05]
Phasen des Zweiten Weltkrieges      0.032        0.000          0.011  [2.50393e-17, 0.000625243]
Methodik & Didaktik                 0.027        0.000          0.027  [1.22354e-31, 9.07914e-09]
Deutsches Kaiserreich               0.026        0.000          0.023    [1.3103e-17, 0.00210508]

properties.ccm:educationalcontext
--------------------------------------------------------------------
                    mean_prob  median_prob  baseline_diff               prob_interval
name                                                                                 
Sekundarstufe I         0.874        0.911          0.099        [0.811731, 0.987644]
Sekundarstufe II        0.839        0.878          0.194        [0.768143, 0.988244]
Berufliche Bildung      0.105        0.080          0.037       [0.0116357, 0.155771]
Hochschule              0.067        0.026          0.034    [0.000195389, 0.0923503]
Erwachsenenbildung      0.054        0.030          0.013    [9.89673e-05, 0.0798472]
Primarstufe             0.041        0.021         -0.815    [7.63122e-06, 0.0586492]
Fortbildung             0.002        0.000         -0.003  [2.37065e-09, 0.000367491]

properties.ccm:educationalintendedenduserrole
--------------------------------------------------------------------
            mean_prob  median_prob  baseline_diff               prob_interval
name                                                                         
Lehrer/in       0.981        0.994          0.653               [0.977388, 1]
Lerner/in       0.869        0.902         -0.066         [0.79724, 0.994676]
Eltern          0.099        0.056         -0.384       [0.0023409, 0.152369]
Verwaltung      0.000        0.000         -0.002  [2.61081e-14, 8.91576e-07]
Berater/in      0.000        0.000         -0.041  [7.67382e-16, 8.29404e-06]
Autor/in        0.000        0.000         -0.001  [8.88453e-21, 5.61577e-08]
andere          0.000        0.000         -0.002  [5.08556e-19, 3.23635e-07]

properties.ccm:oeh_lrt
--------------------------------------------------------------------
                                      mean_prob  median_prob  baseline_diff             prob_interval
name                                                                                                 
Arbeitsblatt                              0.203        0.147          0.084    [0.00532866, 0.328037]
Unterrichtsbaustein                       0.123        0.072         -0.099    [0.00180031, 0.200739]
Material                                  0.116        0.081         -0.328      [0.002623, 0.175548]
Erklärvideo und gefilmtes Experiment      0.101        0.061         -0.101    [0.00156279, 0.153475]
Wiki (dynamisch)                          0.096        0.034          0.061    [0.000243854, 0.13127]
Radio, Podcastfolge und Interview         0.063        0.016         -0.132  [6.84144e-05, 0.0738962]
Webseite                                  0.057        0.034         -0.058   [0.00131109, 0.0839542]

properties.ccm:taxonid
--------------------------------------------------------------------
                  mean_prob  median_prob  baseline_diff              prob_interval
name                                                                              
Geschichte            0.999        1.000          0.723              [0.999185, 1]
Politik               0.148        0.108          0.026      [0.0136279, 0.224194]
Wirtschaftskunde      0.012        0.002          0.007  [7.05656e-07, 0.00952562]
Sozialpädagogik       0.009        0.001          0.008  [3.02026e-06, 0.00551643]
Allgemein             0.009        0.005         -0.298   [0.000184859, 0.0124089]
Ethik                 0.003        0.001         -0.050  [1.46173e-06, 0.00356193]
Deutsch               0.002        0.001         -0.052   [1.30163e-05, 0.0025523]
#+end_example

* Notes / Limitations

** RAM Usage
The service requires roughly 4GB of RAM to operate. This usage should be roughly static with time, though queries will momentarily increase the RAM usage -- proportionally to the number of samples used (up to a maximum, when batching kicks in).

** Cutoffs & Interpretation of Results
Because of the nature of the model, it can be difficult to decide on which predictions shall be counted as actually being predicted to be assigned. This is especially true for categories where a very large or small amount of data points where observed, as the model will essentially replicate these biases in the data. This is why we additionally provide the difference in means to the baseline probabilities (i.e. predictions where the text is empty) -- a larger difference, both positive and negative, indicates a stronger prediction, regardless of the underlying base frequencies. However, a lower difference in means to the baseline may also be a very certain prediction that just so happens to be around the baseline, which is why it can also be helpful to consider the probability credibility interval -- a narrower interval indicates higher certainty, whereas a wider one indicates lower certainty.

** Hierarchical Metadata
While the model can technically predict some hierarchical metadata (i.e. =oeh_lrt= and =curriculum=), these hierarchies are currently flattened, such that any information stemming from the hierarchies is discarded. This may be dealt with at a later date.

* Model Details and Possible Improvements

The model is based on the [[https://pyro.ai/examples/prodlda.html][example implementation]] of [[https://arxiv.org/abs/1703.01488][the ProdLDA model (arXiv:1703.01488)]] in [[https://pyro.ai/][Pyro]], utilizing black-box variational inference. We modified this unsupervised topic model by introducing a linear relationship between the assigned topic mixture and each category of each metadata field to be predicted. Individual categories between different metadata fields are modeled to be independent.

This could be improved in various ways in the future:
1. More topics and larger neural networks. Due to the large size of the newest training data, it may be beneficial to increase the current choice of 500 topics and shallow neural networks with a hidden layer size of 1000, e.g. doubling both or adding additional hidden layers to the encoder.
2. Dependencies between categories (within individual metadata fields and between them) could be modeled. This could improve performance, especially when doing classification on partially labeled data (e.g. some categories or whole metadata fields are already given).
3. The relationship between topic mixture and metadata field categories is drawn from a global, unchanging distribution. Similarly to the variational parameters of the topic mixture, this relationship could instead be drawn from a document-specific distribution through a neural network, thus increasing the expressiveness of the model.
   - Additionally, it may be worthwhile to also try "inverting" the relationship between topics and targets, i.e. draw targets based on document content first, then draw topics based on targets and document content. This could result in more stable prediction results, as the quality of predicted targets are no longer as closely linked to the quality of the predicted topics.
4. The number of topics to be estimated is currently a fixed hyper-parameter. Using a non-parametric hierarchical Dirichlet process (HDP) model instead would allow for a data-specific choice of the number of topics.
5. Introduce information about the hierarchies of the categories, where relevant (currently learning resource type and topic). This should result in more specificity in the predictions and better quality in general. Possibly relevant for this: [[https://dl.acm.org/doi/10.5555/2986459.2986750][Hierarchically supervised latent Dirichlet allocation]].
6. Rather than using the (naive, if pre-processed) bag-of-words representations of documents, utilize modern vectorization methods instead (see [[https://dl.acm.org/doi/abs/10.1145/2911451.2911499][Topic Modeling for Short Texts with Auxiliary Word Embeddings]] or [[https://arxiv.org/abs/2403.03737][Probabilistic Topic Modelling with Transformer Representations]]).
7. Utilize additional metadata for classification, e.g. the mimetype or source.
8. Utilize the metadata that is assigned to the collections, such as their school discipline or educational context.
9. Because predictions of probabilistic models are not just points, but rather a whole probability distribution over the entire probability space, we are currently "throwing away" a lot of potential information. It might be interesting, for example, to visualize the entire distribution over each metadatum's categories, in order to convey the certainty of predictions (a "broader" distribution shape implies less certainty, a "sharper" distribution more).
10. We currently use Python's builtin ~pickle~ for saving / exporting model parameters. Loading these files is generally considered to be unsafe, as they could execute arbitrary Python code. An alternative could be [[https://github.com/huggingface/safetensors][safetensors]].
11. Texts given processed through the REST-API do not run through the same pre-processing pipeline as the training data (repeated tokens are not removed, for example). Instead, they are simply tokenized and filtered according to the set of tokens in the training data. Thus, general prediction results may be slightly worse than expected, even for texts that appear in the training data.
12. The memory usage of training / evaluation is directly proportional to the size of the data 
    
* Installation (through ~Nix Flakes~)

Add this repository to your Flake inputs. This may look like this:
#+begin_src nix
{
  inputs = {
    its-jointprobability = {
      url = "github:openeduhub/its-jointprobability";
      # optional
      # can reduce the total size when installing the application, but may
      # cause problems due to breaking changes in some dependencies
      nixpkgs.follows = "nixpkgs"; 
    };
  };
}
#+end_src

** Standalone Application

The micro-service is provided both as a ~nixpkgs~ overlay and as an output (~packages.${system}.its-jointprobability~). Thus, it may be included through
#+begin_src nix
{
  outputs =
    {
      self,
      nixpkgs,
      its-jointprobability,
      ...
    }:
    let
      system = "x86_64-linux";
      pkgs = nixpkgs.legacyPackages.${system}.extend
        its-jointprobability.overlays.default;
    in
    { };
}
#+end_src

** Python Library

The Python library is also provided as an overlay. Please not that this requires a version of ~nixpkgs~ later than =02b8c7ddb7fe956871fa65466bf8a30fa69ec078=, from 2024-03-14 (i.e. =nixos-24.05= or later, or =nixpkgs-unstable= / =nixos-unstable=).
 
#+begin_src nix
{
  outputs =
    {
      self,
      nixpkgs,
      its-jointprobability,
      ...
    }:
    let
      system = "x86_64-linux";
      pkgs = nixpkgs.legacyPackages.${system}.extend
        its-jointprobability.overlays.python-lib;

      my-python = pkgs.python3.withPackages (
        py-pkgs: with py-pkgs; [
          # some examples
          pandas
          numpy
          # this library
          its-jointprobability
        ]
      );
    in
    { };
}
#+end_src

